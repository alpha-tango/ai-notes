{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.tensorflow.org/get_started/get_started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensors\n",
    "\n",
    "### In the tutorial\n",
    "```The central unit of data in TensorFlow is the tensor. A tensor consists of a set of primitive values shaped into an array of any number of dimensions. A tensor's rank is its number of dimensions.```\n",
    "### From wikipedia\n",
    "```In mathematics, tensors are geometric objects that describe linear relations between geometric vectors, scalars, and other tensors. Elementary examples of such relations include the dot product, the cross product, and linear maps. Geometric vectors, often used in physics and engineering applications, and scalars themselves are also tensors.```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computational Graphs\n",
    "\n",
    "```A computational graph is a series of TensorFlow operations arranged into a graph of nodes. Let's build a simple computational graph. Each node takes zero or more tensors as inputs and produces a tensor as an output.```\n",
    "```One type of node is a constant. Like all TensorFlow constants, it takes no inputs, and it outputs a value it stores internally.```\n",
    "Its value can never change, and it gets initialized as soon as you create it (we get more on that later)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Const:0\", shape=(), dtype=float32) Tensor(\"Const_1:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "\n",
    "node1 = tf.constant(3.0, dtype=tf.float32)\n",
    "node2 = tf.constant(4.0) # also tf.float32 implicitly\n",
    "print(node1, node2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```A session encapsulates the control and state of the TensorFlow runtime.```\n",
    "You can run a computational graph within a session, at which point everything\n",
    "within the computational graph gets evaluated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.0, 4.0]\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "print(sess.run([node1, node2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another type of node is an operation node. You can get fancier by combining\n",
    "constant nodes with operation nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node3:  Tensor(\"Add:0\", shape=(), dtype=float32)\n",
      "sess.run(node3): 7.0\n"
     ]
    }
   ],
   "source": [
    "node3 = tf.add(node1, node2)\n",
    "print(\"node3: \", node3) # this prints the object and shape gobbledygook\n",
    "print(\"sess.run(node3):\", sess.run(node3)) # this actually evaluates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next they explain that TensorBoards are basically just visualizations of the Flow / ComputationalGraph / DAG. They look much like Airflow or KNIME.\n",
    "Weirdly, although they're called \"Flow\", the TensorBoard examples here don't have arrows, and go bottom to top, which is visually very counter-intuitive to me. But, maybe they're meant to be flexible enough to go both directions\n",
    "(like neural networks go forwards and then backprop backwards) ...so maybe the point is to not have one \"obvious\" direction and one \"counter-intuitive\" direction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you wanted to provide values for nodes 1 and 2 that change between runs and you don't want to hardcode that, you can make a placeholder node in your graph. When you run the session, you provide the values for those nodes.\n",
    "like arguments. (See further down).\n",
    "You must provide the datatype when you make a placeholder, here's the list of datatypes: https://www.tensorflow.org/versions/r0.12/resources/dims_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Placeholder_6:0\", dtype=float32) Tensor(\"Placeholder_7:0\", dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "a = tf.placeholder(tf.float32)\n",
    "b = tf.placeholder(tf.float32)\n",
    "adder_node = a + b  # alternative to tf.add(a, b)\n",
    "print(a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then the tutorial says to use the feed_dict argument to get the values you into the placeholder nodes. The tutorial uses a fixed argument here, but the docs have a keyword argument. Turns out they both work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.5\n",
      "7.5\n",
      "[ 3.  7.  8.]\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(adder_node, {a: 3, b: 4.5})) # works, returns a floats\n",
    "print(sess.run(adder_node, feed_dict={a: 3, b: 4.5})) # also works, also returns float\n",
    "print(sess.run(adder_node, {a: [1, 3, 4], b: [2, 4, 4]})) # returns numpy array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we declared a and b to be floats. What's going on in that last example is that we can provide multiple values of them at once. With one call to `sess.run` you can get results from multiple sets of inputs. More examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.0\n",
      "6.0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-c37442118158>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madder_node\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m9\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# returns float\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madder_node\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# returns float\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madder_node\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# no good!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/annepope/.virtualenvs/mlearn/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/annepope/.virtualenvs/mlearn/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1087\u001b[0m             \u001b[0mfeed_handles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubfeed_val\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1088\u001b[0m           \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1089\u001b[0;31m             \u001b[0mnp_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubfeed_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1090\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1091\u001b[0m           if (not is_tensor_handle_feed and\n",
      "\u001b[0;32m/Users/annepope/.virtualenvs/mlearn/lib/python2.7/site-packages/numpy/core/numeric.pyc\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    529\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     \"\"\"\n\u001b[0;32m--> 531\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "print(sess.run(adder_node, {a: 8, b: 9})) # returns float\n",
    "print(sess.run(adder_node, {a: 1/2, b: 6})) # returns float\n",
    "print(sess.run(adder_node, {a: [1, 3, 4], b: [2, 4, [4]]})) # no good!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That last guy isn't a boxy enough array of arrays, so what would\n",
    "adding those mean?\n",
    "Next we're going to get fancier with more nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"mul:0\", dtype=float32)\n",
      "22.5\n"
     ]
    }
   ],
   "source": [
    "add_and_triple = adder_node * 3.\n",
    "print(add_and_triple)\n",
    "print(sess.run(add_and_triple, {a: 3, b: 4.5}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a good summary from the tutorial:\n",
    "```In machine learning we will typically want a model that can take arbitrary inputs, such as the one above. To make the model trainable, we need to be able to modify the graph to get new outputs with the same input. Variables allow us to add trainable parameters to a graph.```\n",
    "Key point: the constant nodes or placeholder nodes won't change value throughout the run of a session. If we want something that will change value, we'll use variable nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable_2:0' shape=(1,) dtype=float32_ref>\n"
     ]
    }
   ],
   "source": [
    "W = tf.Variable([.3], dtype=tf.float32)\n",
    "print(W)\n",
    "b = tf.Variable([-.3], dtype=tf.float32)\n",
    "# my_variable = tf.get_variable(\"my_variable\", [1, 2, 3])\n",
    "x = tf.placeholder(tf.float32)\n",
    "linear_model = W*x + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In TensorFlow, variables aren't initialized until you say that they should be. Why? They don't say in the tutorial, but here's from the docs:\n",
    "```Explicit initialization is otherwise useful because it allows you not to\n",
    "rerun potentially expensive initializers when reloading a model from a\n",
    "checkpoint as well as allowing determinism when randomly-initialized\n",
    "variables are shared in a distributed setting.```\n",
    "(https://www.tensorflow.org/programmers_guide/variables)\n",
    "\n",
    "Here's how you say that the variables should all be initialized:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.          0.30000001  0.60000002  0.90000004]\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "print(sess.run(linear_model, {x: [1, 2, 3, 4]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far we have:\n",
    "* created a trainable model\n",
    "* run the model\n",
    "\n",
    "Next we'll want to evaluate the model against some training data. For that, we'll need to:\n",
    "* create something to hold the correct labels / classifications / output values\n",
    "* write an error function. in this case ```we'll use a standard loss model for linear regression, which sums the squares of the deltas between the current model and the provided data.```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.66\n"
     ]
    }
   ],
   "source": [
    "y = tf.placeholder(tf.float32) # this will hold the correct output values\n",
    "squared_deltas = tf.square(linear_model - y)\n",
    "loss = tf.reduce_sum(squared_deltas)\n",
    "print(sess.run(loss, {x: [1,2,3,4], y: [0, -1, -2, -3]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "fixW = tf.assign(W, [-1.])\n",
    "fixb = tf.assign(b, [1.])\n",
    "sess.run([fixW, fixb])\n",
    "print(sess.run(loss, {x: [1, 2, 3, 4], y: [0, -1, -2, -3]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tf.train API\n",
    "\n",
    "```the whole point of machine learning is to find the correct model parameters automatically.```\n",
    "\n",
    "To that end, TensorFlow provides **optimizers** that slowly change each variable to minimize loss and approach the correct answer. \n",
    "\n",
    "According to the tutorial, \"the simplest optimizer is **gradient descent**. It modifies each variable according to the magnitude of the derivative of loss with respect to that variable.\" \n",
    "\n",
    "That is not fun to do by hand, so aren't you glad that's taken care of for you?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(0.01) # that's the magnitude of the learning step\n",
    "train = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([-0.9999969], dtype=float32), array([ 0.99999082], dtype=float32)]\n",
      "W: [-0.9999969] b: [ 0.99999082] loss: 5.69997e-11\n"
     ]
    }
   ],
   "source": [
    "sess.run(init) # we fixed the values above so now we're unfixing\n",
    "for i in range(1000):\n",
    "    sess.run(train, {x: [1, 2, 3, 4], y: [0, -1, -2, -3]})\n",
    "    \n",
    "print(sess.run([W, b]))\n",
    "\n",
    "# evaluate training accuracy\n",
    "curr_W, curr_b, curr_loss = sess.run([W, b, loss], {x: [1, 2, 3, 4], y: [0, -1, -2, -3]})\n",
    "\n",
    "print(\"W: %s b: %s loss: %s\"%(curr_W, curr_b, curr_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://www.tensorflow.org/images/getting_started_final.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tf.estimator\n",
    "\n",
    "This is a TensorFlow library that includes features to manage data sets, training, evaluating, etc. so that more of this is abstracted away as something we need to worry about. An **estimator** is basically a front-end/shortcut to train/fit the model and evaluate it (using statistical inference) using a particular model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1: declare a list of features** There are many kinds of features, and you could have a very long list if you chose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = [tf.feature_column.numeric_column(\"x\", shape=[1])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2: choose an estimator**. There are lots of ready-defined types to use, in the tutorial they use a linear regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/2j/604kc25x1fqbc542297fpq1c0000gn/T/tmpTsHUX4\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_task_type': 'worker', '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x114a98f50>, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_master': '', '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_model_dir': '/var/folders/2j/604kc25x1fqbc542297fpq1c0000gn/T/tmpTsHUX4', '_save_summary_steps': 100}\n"
     ]
    }
   ],
   "source": [
    "estimator = tf.estimator.LinearRegressor(feature_columns=feature_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3: set up our training and test data sets**. tf.estimator provides helper functions for this. Note that `num_epochs` is how many batches of data you want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array([1., 2., 3., 4.])\n",
    "y_train = np.array([0., -1., -2., -3.])\n",
    "x_eval = np.array([2., 5., 8., 1.])\n",
    "y_eval = np.array([-1.01, -4.1, -7, 0.])\n",
    "\n",
    "input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    {\"x\": x_train}, y_train, batch_size=4, num_epochs=None, shuffle=True)\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    {\"x\": x_train}, y_train, batch_size=4, num_epochs=1000, shuffle=False)\n",
    "eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    {\"x\": x_eval}, y_eval, batch_size=4, num_epochs=1000, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 4: train the model**. Here we're specifying 1000 training steps or iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /var/folders/2j/604kc25x1fqbc542297fpq1c0000gn/T/tmpTsHUX4/model.ckpt.\n",
      "INFO:tensorflow:loss = 15.0, step = 1\n",
      "INFO:tensorflow:global_step/sec: 629.565\n",
      "INFO:tensorflow:loss = 0.578425, step = 101 (0.173 sec)\n",
      "INFO:tensorflow:global_step/sec: 679.764\n",
      "INFO:tensorflow:loss = 0.0305686, step = 201 (0.135 sec)\n",
      "INFO:tensorflow:global_step/sec: 818.343\n",
      "INFO:tensorflow:loss = 0.00842404, step = 301 (0.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 936.461\n",
      "INFO:tensorflow:loss = 0.00361122, step = 401 (0.107 sec)\n",
      "INFO:tensorflow:global_step/sec: 977.47\n",
      "INFO:tensorflow:loss = 0.000888144, step = 501 (0.102 sec)\n",
      "INFO:tensorflow:global_step/sec: 1123.65\n",
      "INFO:tensorflow:loss = 0.000176936, step = 601 (0.089 sec)\n",
      "INFO:tensorflow:global_step/sec: 1073.38\n",
      "INFO:tensorflow:loss = 3.17232e-05, step = 701 (0.093 sec)\n",
      "INFO:tensorflow:global_step/sec: 1099.35\n",
      "INFO:tensorflow:loss = 4.2329e-06, step = 801 (0.091 sec)\n",
      "INFO:tensorflow:global_step/sec: 1019.64\n",
      "INFO:tensorflow:loss = 1.59816e-06, step = 901 (0.098 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into /var/folders/2j/604kc25x1fqbc542297fpq1c0000gn/T/tmpTsHUX4/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 1.33065e-07.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.linear.LinearRegressor at 0x114ab8650>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.train(input_fn=input_fn, steps=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 5: evaluate performance.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2017-12-05-01:55:05\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/2j/604kc25x1fqbc542297fpq1c0000gn/T/tmpTsHUX4/model.ckpt-1000\n",
      "INFO:tensorflow:Finished evaluation at 2017-12-05-01:55:07\n",
      "INFO:tensorflow:Saving dict for global step 1000: average_loss = 5.19178e-08, global_step = 1000, loss = 2.07671e-07\n",
      "INFO:tensorflow:Starting evaluation at 2017-12-05-01:55:07\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/2j/604kc25x1fqbc542297fpq1c0000gn/T/tmpTsHUX4/model.ckpt-1000\n",
      "INFO:tensorflow:Finished evaluation at 2017-12-05-01:55:08\n",
      "INFO:tensorflow:Saving dict for global step 1000: average_loss = 0.00254646, global_step = 1000, loss = 0.0101858\n",
      "train metrics: {'average_loss': 5.1917795e-08, 'global_step': 1000, 'loss': 2.0767118e-07}\n",
      "eval metrics: {'average_loss': 0.0025464611, 'global_step': 1000, 'loss': 0.010185844}\n"
     ]
    }
   ],
   "source": [
    "train_metrics = estimator.evaluate(input_fn=train_input_fn)\n",
    "eval_metrics = estimator.evaluate(input_fn=eval_input_fn)\n",
    "print(\"train metrics: %r\"% train_metrics)\n",
    "print(\"eval metrics: %r\"% eval_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom models\n",
    "\n",
    "The tutorial gives a walkthrough of how to create a custom model, if the model (like `LinearRegressor`) isn't built into the TF API (or if, say, you wanted to adapt the implementation of it for whatever reason.\n",
    "\n",
    "The generic class is the `Estimator` class, so `LinearRegressor` is actual a sub-class of `Estimator`. But to make a custom model, you don't need to subclass `Estimator` -- you can just provide a function, `model_fn`, that tells the estimator `how it can evaluate predictions, training steps, and loss.`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1: declare a list of features** (same as above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = [tf.feature_column.numeric_column(\"x\", shape=[1])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: define an estimator (here's where our code will be different from the above standard walkthrough)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/2j/604kc25x1fqbc542297fpq1c0000gn/T/tmp8yQJng\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_task_type': 'worker', '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x11570f9d0>, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_master': '', '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_model_dir': '/var/folders/2j/604kc25x1fqbc542297fpq1c0000gn/T/tmp8yQJng', '_save_summary_steps': 100}\n"
     ]
    }
   ],
   "source": [
    "def model_fn(features, labels, mode):\n",
    "    # build a linear model\n",
    "    W = tf.get_variable(\"W\", [1], dtype=tf.float64)\n",
    "    b = tf.get_variable(\"b\", [1], dtype=tf.float64)\n",
    "    y = W*features['x'] + b\n",
    "    \n",
    "    # define the loss (\"loss sub-graph\")\n",
    "    loss = tf.reduce_sum(tf.square(y - labels))\n",
    "    \n",
    "    # define training (\"training sub-graph\")\n",
    "    global_step = tf.train.get_global_step()  # this tracks what training iteration we're on\n",
    "    optimizer = tf.train.GradientDescentOptimizer(0.01)\n",
    "    train = tf.group(optimizer.minimize(loss),\n",
    "                   tf.assign_add(global_step, 1)) # this just groups the two operations, loss minimizing and incrementing the step\n",
    "    \n",
    "    # EstimatorSpec is what connects the sub-graphs we just defined above\n",
    "    # to get the ultimate functionality\n",
    "    return tf.estimator.EstimatorSpec(\n",
    "        mode=mode,\n",
    "        predictions=y,\n",
    "        loss=loss,\n",
    "        train_op=train\n",
    "    )\n",
    "\n",
    "estimator = tf.estimator.Estimator(model_fn=model_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3: set up our training and test data sets** (same as above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array([1., 2., 3., 4.])\n",
    "y_train = np.array([0., -1., -2., -3.])\n",
    "x_eval = np.array([2., 5., 8., 1.])\n",
    "y_eval = np.array([-1.01, -4.1, -7., 0.])\n",
    "input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    {\"x\": x_train}, y_train, batch_size=4, num_epochs=None, shuffle=True)\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    {\"x\": x_train}, y_train, batch_size=4, num_epochs=1000, shuffle=False)\n",
    "eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    {\"x\": x_eval}, y_eval, batch_size=4, num_epochs=1000, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 4: train the model** (same as above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /var/folders/2j/604kc25x1fqbc542297fpq1c0000gn/T/tmp8yQJng/model.ckpt.\n",
      "INFO:tensorflow:loss = 12.4964003622, step = 1\n",
      "INFO:tensorflow:global_step/sec: 566.717\n",
      "INFO:tensorflow:loss = 0.440538517976, step = 101 (0.129 sec)\n",
      "INFO:tensorflow:global_step/sec: 853.045\n",
      "INFO:tensorflow:loss = 0.0263902392921, step = 201 (0.117 sec)\n",
      "INFO:tensorflow:global_step/sec: 984.28\n",
      "INFO:tensorflow:loss = 0.0024488436504, step = 301 (0.102 sec)\n",
      "INFO:tensorflow:global_step/sec: 958.323\n",
      "INFO:tensorflow:loss = 8.65175725917e-05, step = 401 (0.104 sec)\n",
      "INFO:tensorflow:global_step/sec: 916.876\n",
      "INFO:tensorflow:loss = 4.00314831506e-06, step = 501 (0.110 sec)\n",
      "INFO:tensorflow:global_step/sec: 949.045\n",
      "INFO:tensorflow:loss = 1.74375072614e-06, step = 601 (0.105 sec)\n",
      "INFO:tensorflow:global_step/sec: 961.899\n",
      "INFO:tensorflow:loss = 8.49645655008e-08, step = 701 (0.104 sec)\n",
      "INFO:tensorflow:global_step/sec: 955.566\n",
      "INFO:tensorflow:loss = 1.30717873041e-08, step = 801 (0.105 sec)\n",
      "INFO:tensorflow:global_step/sec: 1125.72\n",
      "INFO:tensorflow:loss = 2.16540350713e-09, step = 901 (0.089 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into /var/folders/2j/604kc25x1fqbc542297fpq1c0000gn/T/tmp8yQJng/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 7.58937991135e-11.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.estimator.Estimator at 0x114cb2b50>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.train(input_fn=input_fn, steps=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 5: evaluate performance** (same as above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2017-12-05-02:16:10\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/2j/604kc25x1fqbc542297fpq1c0000gn/T/tmp8yQJng/model.ckpt-1000\n",
      "INFO:tensorflow:Finished evaluation at 2017-12-05-02:16:11\n",
      "INFO:tensorflow:Saving dict for global step 1000: global_step = 1000, loss = 1.21545e-10\n",
      "INFO:tensorflow:Starting evaluation at 2017-12-05-02:16:11\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/2j/604kc25x1fqbc542297fpq1c0000gn/T/tmp8yQJng/model.ckpt-1000\n",
      "INFO:tensorflow:Finished evaluation at 2017-12-05-02:16:12\n",
      "INFO:tensorflow:Saving dict for global step 1000: global_step = 1000, loss = 0.0101012\n",
      "train metrics: {'loss': 1.2154536e-10, 'global_step': 1000}\n",
      "eval metrics: {'loss': 0.010101224, 'global_step': 1000}\n"
     ]
    }
   ],
   "source": [
    "train_metrics = estimator.evaluate(input_fn=train_input_fn)\n",
    "eval_metrics = estimator.evaluate(input_fn=eval_input_fn)\n",
    "print(\"train metrics: %r\"% train_metrics)\n",
    "print(\"eval metrics: %r\"% eval_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
